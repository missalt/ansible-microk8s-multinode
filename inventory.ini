[syslab]
host1
host2
host3

[syslab:vars]
master_node=master_node

# should be defined at runtime using --extra-vars "ansible_user=realuser" 
ansible_user=username 
# should be defined at runtime using --extra-vars "ansible_password=realpassword" 
ansible_password=password
ansible_ssh_common_args='-o StrictHostKeyChecking=no'

# PLEASE USE THIS WITH CAUTION AND ONLY IN DEV ENVIRONMENTS, THIS IS NOT FIT FOR PRODUCTION AS IT COMPROMISES YOUR PRIVATE SSH KEY AND ALLOWS WORKER-TO-MASTER SSH CONTROL
# this copies your host machines private and public SSH-Key (path defined below) to all cluster machines, allowing passwordless remote control of all machines from your control node and among the cluster nodes (worker and master)
# this script wont work without this option, since the task "Initialize Master Node / Get Token" requires delegation of tasks via SSH from the worker to the master nodes. Since my use case was just for testing purposes, I was fine with this. If you want to use this script for production, I would be happy to hear your thoughts on other options. :) 
distribute_ssh_keys=true 
control_node_ssh_dir=/path/to/.ssh/

# in environments with low persistent storage (e.g. raspberry pi's), Pods might be evicted off worker nodes automatically due to disk pressure on the nodes. This lowers the eviction-hard threshold of the kubelet to below 0%, which effectively disables eviction due to disk pressure. Use with Caution.
disable_eviction_on_diskpressure=true 